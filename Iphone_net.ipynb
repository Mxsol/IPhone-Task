{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vZ-cDGtffZ8j",
    "outputId": "8d9c0730-d6c1-4766-8e69-696b3bb1214b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from keras.applications import MobileNet, ResNet50\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "EvPPca9vDSBB",
    "outputId": "92d49bfc-84f6-4e57-c2a7-a8714af8a368",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43486 images belonging to 2 classes.\n",
      "Found 10752 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'Data/Tr/'\n",
    "test_data_dir = 'Data/Te/'\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    brightness_range=[0.3,1.5],\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True) \n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    test_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False) # set as validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to use ResNet50 with pretrained weights from imagenet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "s0PiOum4FbwK",
    "outputId": "4620ec3b-7efc-481e-93b4-4a5cfc0ff883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(weights='imagenet', include_top = False, \n",
    "                     input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "0hB2V5tzqz12",
    "outputId": "28a8a2cb-58b5-42cf-8b7e-2c7b5d9867cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also tried MobileNet, but decided to use the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/keras_applications/mobilenet.py:206: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#base_model = MobileNet(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKlPn2ICfqfJ"
   },
   "outputs": [],
   "source": [
    "#x=base_model.output\n",
    "#x=layers.GlobalAveragePooling2D()(x)\n",
    "#x=layers.Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "#x=layers.Dense(1024,activation='relu')(x) #dense layer 2\n",
    "#x=layers.Dense(512,activation='relu')(x) #dense layer 3\n",
    "#preds=layers.Dense(1,activation='sigmoid')(x) #final layer with softmax activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2=models.Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in base_model.layers:\n",
    "    #layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created AUC metric in order to use in the training, because it is not among the standard ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAt_DL5Cjn4V"
   },
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7dQ-t4_SzwM"
   },
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just feeling safer with checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15tFdSS8DTXo"
   },
   "outputs": [],
   "source": [
    "filepath=\"mynetfin-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max', save_weights_only=False,period = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the model with our own last layer. It is also reasonable to freeze the layers (that what we wanted from the beginning) in order to have pretrained weights and save a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7a23HAfbfjR7"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "DlhEei84IrK0",
    "outputId": "846274ae-d9a4-4de9-aff9-c0c3b595e2f2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "7OOsszsjIw0v",
    "outputId": "e7171ba8-0f79-420d-ccbb-81d1406a391d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 127s 637ms/step - loss: 0.5437 - acc: 0.7195 - auc: 0.7207 - val_loss: 3.0485 - val_acc: 0.0000e+00 - val_auc: 0.5608\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 130s 651ms/step - loss: 0.4734 - acc: 0.7719 - auc: 0.5045 - val_loss: 1.9806 - val_acc: 0.3747 - val_auc: 0.5172\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 120s 598ms/step - loss: 0.4500 - acc: 0.7894 - auc: 0.5715 - val_loss: 0.0233 - val_acc: 1.0000 - val_auc: 0.6502\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 124s 621ms/step - loss: 0.4367 - acc: 0.7973 - auc: 0.7003 - val_loss: 1.7991 - val_acc: 0.3600 - val_auc: 0.7001\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 140s 698ms/step - loss: 0.4184 - acc: 0.8058 - auc: 0.6876 - val_loss: 2.3260 - val_acc: 0.0147 - val_auc: 0.6808\n",
      "\n",
      "Epoch 00005: val_auc improved from -inf to 0.68079, saving model to mynetfin-05-0.01.hdf5\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 120s 599ms/step - loss: 0.4132 - acc: 0.8109 - auc: 0.6754 - val_loss: 0.0556 - val_acc: 1.0000 - val_auc: 0.6937\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 120s 598ms/step - loss: 0.3932 - acc: 0.8182 - auc: 0.7098 - val_loss: 1.1443 - val_acc: 0.7200 - val_auc: 0.7281\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 128s 642ms/step - loss: 0.3919 - acc: 0.8097 - auc: 0.7262 - val_loss: 3.4732 - val_acc: 0.0000e+00 - val_auc: 0.7110\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 126s 628ms/step - loss: 0.3843 - acc: 0.8173 - auc: 0.6981 - val_loss: 1.4422 - val_acc: 0.6547 - val_auc: 0.6964\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 119s 597ms/step - loss: 0.3786 - acc: 0.8253 - auc: 0.7089 - val_loss: 0.0140 - val_acc: 1.0000 - val_auc: 0.7238\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.68079 to 0.72380, saving model to mynetfin-10-1.00.hdf5\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 123s 613ms/step - loss: 0.3781 - acc: 0.8278 - auc: 0.7369 - val_loss: 3.8793 - val_acc: 0.0800 - val_auc: 0.7264\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 131s 654ms/step - loss: 0.3696 - acc: 0.8314 - auc: 0.7134 - val_loss: 2.5915 - val_acc: 0.2947 - val_auc: 0.7070\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 119s 597ms/step - loss: 0.3630 - acc: 0.8372 - auc: 0.7082 - val_loss: 0.0613 - val_acc: 1.0000 - val_auc: 0.7137\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 121s 605ms/step - loss: 0.3635 - acc: 0.8311 - auc: 0.7188 - val_loss: 2.1052 - val_acc: 0.4400 - val_auc: 0.7227\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 133s 667ms/step - loss: 0.3602 - acc: 0.8339 - auc: 0.7183 - val_loss: 3.2772 - val_acc: 0.0000e+00 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.72380\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 117s 585ms/step - loss: 0.3627 - acc: 0.8316 - auc: 0.7086 - val_loss: 0.2545 - val_acc: 0.9347 - val_auc: 0.7137\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 121s 607ms/step - loss: 0.3424 - acc: 0.8455 - auc: 0.7202 - val_loss: 0.6801 - val_acc: 0.8000 - val_auc: 0.7254\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 126s 630ms/step - loss: 0.3659 - acc: 0.8303 - auc: 0.7269 - val_loss: 3.1309 - val_acc: 0.0000e+00 - val_auc: 0.7235\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 128s 641ms/step - loss: 0.3625 - acc: 0.8316 - auc: 0.7198 - val_loss: 1.6571 - val_acc: 0.5747 - val_auc: 0.7178\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 119s 594ms/step - loss: 0.3429 - acc: 0.8464 - auc: 0.7225 - val_loss: 0.0637 - val_acc: 1.0000 - val_auc: 0.7254\n",
      "\n",
      "Epoch 00020: val_auc improved from 0.72380 to 0.72535, saving model to mynetfin-20-1.00.hdf5\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 123s 615ms/step - loss: 0.3432 - acc: 0.8457 - auc: 0.7280 - val_loss: 3.0952 - val_acc: 0.1600 - val_auc: 0.7261\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 130s 649ms/step - loss: 0.3385 - acc: 0.8438 - auc: 0.7217 - val_loss: 2.4753 - val_acc: 0.2147 - val_auc: 0.7193\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 121s 605ms/step - loss: 0.3417 - acc: 0.8439 - auc: 0.7190 - val_loss: 0.0831 - val_acc: 1.0000 - val_auc: 0.7213\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 119s 596ms/step - loss: 0.3311 - acc: 0.8498 - auc: 0.7238 - val_loss: 1.4994 - val_acc: 0.5200 - val_auc: 0.7258\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 132s 658ms/step - loss: 0.3326 - acc: 0.8477 - auc: 0.7248 - val_loss: 1.9549 - val_acc: 0.0000e+00 - val_auc: 0.7263\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.72535 to 0.72626, saving model to mynetfin-25-0.00.hdf5\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 120s 598ms/step - loss: 0.3396 - acc: 0.8486 - auc: 0.7275 - val_loss: 0.4273 - val_acc: 0.8547 - val_auc: 0.7290\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 123s 614ms/step - loss: 0.3345 - acc: 0.8519 - auc: 0.7308 - val_loss: 0.3814 - val_acc: 0.8800 - val_auc: 0.7329\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 125s 626ms/step - loss: 0.3351 - acc: 0.8465 - auc: 0.7344 - val_loss: 2.1757 - val_acc: 0.0000e+00 - val_auc: 0.7351\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 125s 627ms/step - loss: 0.3240 - acc: 0.8550 - auc: 0.7358 - val_loss: 1.3201 - val_acc: 0.4947 - val_auc: 0.7361\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 121s 603ms/step - loss: 0.3266 - acc: 0.8522 - auc: 0.7376 - val_loss: 0.0981 - val_acc: 1.0000 - val_auc: 0.7394\n",
      "\n",
      "Epoch 00030: val_auc improved from 0.72626 to 0.73942, saving model to mynetfin-30-1.00.hdf5\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 122s 611ms/step - loss: 0.3279 - acc: 0.8542 - auc: 0.7413 - val_loss: 2.1487 - val_acc: 0.2400 - val_auc: 0.7412\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 136s 681ms/step - loss: 0.3136 - acc: 0.8536 - auc: 0.7401 - val_loss: 2.0046 - val_acc: 0.1347 - val_auc: 0.7405\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.3371 - acc: 0.8525 - auc: 0.7410 - val_loss: 0.0439 - val_acc: 1.0000 - val_auc: 0.7439\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 118s 589ms/step - loss: 0.3281 - acc: 0.8528 - auc: 0.7466 - val_loss: 0.9750 - val_acc: 0.6000 - val_auc: 0.7477\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 129s 645ms/step - loss: 0.3217 - acc: 0.8552 - auc: 0.7484 - val_loss: 2.6498 - val_acc: 0.0000e+00 - val_auc: 0.7474\n",
      "\n",
      "Epoch 00035: val_auc improved from 0.73942 to 0.74741, saving model to mynetfin-35-0.00.hdf5\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 120s 601ms/step - loss: 0.3065 - acc: 0.8656 - auc: 0.7466 - val_loss: 0.7982 - val_acc: 0.7747 - val_auc: 0.7475\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 117s 585ms/step - loss: 0.3161 - acc: 0.8613 - auc: 0.7504 - val_loss: 0.1898 - val_acc: 0.9600 - val_auc: 0.7518\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 122s 612ms/step - loss: 0.3041 - acc: 0.8636 - auc: 0.7532 - val_loss: 3.1838 - val_acc: 0.0000e+00 - val_auc: 0.7509\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 126s 629ms/step - loss: 0.3138 - acc: 0.8613 - auc: 0.7487 - val_loss: 1.2075 - val_acc: 0.4147 - val_auc: 0.7495\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.3232 - acc: 0.8564 - auc: 0.7503 - val_loss: 0.0532 - val_acc: 1.0000 - val_auc: 0.7522\n",
      "\n",
      "Epoch 00040: val_auc improved from 0.74741 to 0.75220, saving model to mynetfin-40-1.00.hdf5\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 118s 589ms/step - loss: 0.3136 - acc: 0.8609 - auc: 0.7542 - val_loss: 1.9589 - val_acc: 0.3200 - val_auc: 0.7545\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 133s 665ms/step - loss: 0.3076 - acc: 0.8628 - auc: 0.7536 - val_loss: 2.5360 - val_acc: 0.0547 - val_auc: 0.7527\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2974 - acc: 0.8675 - auc: 0.7522 - val_loss: 0.0421 - val_acc: 1.0000 - val_auc: 0.7548\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.3092 - acc: 0.8625 - auc: 0.7571 - val_loss: 0.9768 - val_acc: 0.6800 - val_auc: 0.7587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "200/200 [==============================] - 127s 633ms/step - loss: 0.3099 - acc: 0.8613 - auc: 0.7588 - val_loss: 3.4524 - val_acc: 0.0000e+00 - val_auc: 0.7562\n",
      "\n",
      "Epoch 00045: val_auc improved from 0.75220 to 0.75616, saving model to mynetfin-45-0.00.hdf5\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 121s 606ms/step - loss: 0.3004 - acc: 0.8620 - auc: 0.7537 - val_loss: 1.0221 - val_acc: 0.6947 - val_auc: 0.7537\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.3083 - acc: 0.8658 - auc: 0.7555 - val_loss: 0.1601 - val_acc: 1.0000 - val_auc: 0.7562\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 121s 603ms/step - loss: 0.2998 - acc: 0.8676 - auc: 0.7570 - val_loss: 2.9359 - val_acc: 0.0400 - val_auc: 0.7557\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 128s 639ms/step - loss: 0.2974 - acc: 0.8672 - auc: 0.7542 - val_loss: 2.2970 - val_acc: 0.3347 - val_auc: 0.7525\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.3057 - acc: 0.8650 - auc: 0.7530 - val_loss: 0.0891 - val_acc: 1.0000 - val_auc: 0.7541\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.75616\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2969 - acc: 0.8650 - auc: 0.7553 - val_loss: 1.0567 - val_acc: 0.4000 - val_auc: 0.7560\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 132s 662ms/step - loss: 0.3122 - acc: 0.8630 - auc: 0.7570 - val_loss: 2.1156 - val_acc: 0.0000e+00 - val_auc: 0.7574\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.2874 - acc: 0.8767 - auc: 0.7579 - val_loss: 0.1603 - val_acc: 0.9747 - val_auc: 0.7589\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.3004 - acc: 0.8645 - auc: 0.7598 - val_loss: 0.5951 - val_acc: 0.7600 - val_auc: 0.7605\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 125s 626ms/step - loss: 0.2886 - acc: 0.8756 - auc: 0.7612 - val_loss: 1.7755 - val_acc: 0.0000e+00 - val_auc: 0.7621\n",
      "\n",
      "Epoch 00055: val_auc improved from 0.75616 to 0.76209, saving model to mynetfin-55-0.00.hdf5\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 122s 611ms/step - loss: 0.2957 - acc: 0.8675 - auc: 0.7629 - val_loss: 0.7263 - val_acc: 0.6147 - val_auc: 0.7638\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.3023 - acc: 0.8638 - auc: 0.7643 - val_loss: 0.1754 - val_acc: 1.0000 - val_auc: 0.7648\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 119s 597ms/step - loss: 0.3090 - acc: 0.8602 - auc: 0.7653 - val_loss: 1.7225 - val_acc: 0.1200 - val_auc: 0.7658\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 129s 647ms/step - loss: 0.2752 - acc: 0.8792 - auc: 0.7664 - val_loss: 1.9223 - val_acc: 0.2547 - val_auc: 0.7660\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2941 - acc: 0.8708 - auc: 0.7662 - val_loss: 0.0661 - val_acc: 1.0000 - val_auc: 0.7675\n",
      "\n",
      "Epoch 00060: val_auc improved from 0.76209 to 0.76745, saving model to mynetfin-60-1.00.hdf5\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 118s 588ms/step - loss: 0.2840 - acc: 0.8761 - auc: 0.7688 - val_loss: 1.5518 - val_acc: 0.4800 - val_auc: 0.7695\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 131s 654ms/step - loss: 0.2873 - acc: 0.8729 - auc: 0.7689 - val_loss: 2.9199 - val_acc: 0.0000e+00 - val_auc: 0.7678\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2879 - acc: 0.8725 - auc: 0.7667 - val_loss: 0.3528 - val_acc: 0.8947 - val_auc: 0.7675\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2853 - acc: 0.8770 - auc: 0.7687 - val_loss: 0.4837 - val_acc: 0.8400 - val_auc: 0.7697\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 124s 618ms/step - loss: 0.2880 - acc: 0.8722 - auc: 0.7702 - val_loss: 3.0224 - val_acc: 0.0000e+00 - val_auc: 0.7690\n",
      "\n",
      "Epoch 00065: val_auc improved from 0.76745 to 0.76898, saving model to mynetfin-65-0.00.hdf5\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 124s 619ms/step - loss: 0.2810 - acc: 0.8803 - auc: 0.7678 - val_loss: 1.4634 - val_acc: 0.5347 - val_auc: 0.7672\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.2718 - acc: 0.8814 - auc: 0.7682 - val_loss: 0.0133 - val_acc: 1.0000 - val_auc: 0.7703\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.2910 - acc: 0.8720 - auc: 0.7723 - val_loss: 2.3033 - val_acc: 0.2000 - val_auc: 0.7721\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 131s 655ms/step - loss: 0.2817 - acc: 0.8781 - auc: 0.7713 - val_loss: 2.7524 - val_acc: 0.1747 - val_auc: 0.7699\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2775 - acc: 0.8833 - auc: 0.7695 - val_loss: 0.0425 - val_acc: 1.0000 - val_auc: 0.7710\n",
      "\n",
      "Epoch 00070: val_auc improved from 0.76898 to 0.77096, saving model to mynetfin-70-1.00.hdf5\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2833 - acc: 0.8745 - auc: 0.7724 - val_loss: 1.4552 - val_acc: 0.5600 - val_auc: 0.7734\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 130s 648ms/step - loss: 0.2914 - acc: 0.8734 - auc: 0.7728 - val_loss: 2.6011 - val_acc: 0.0000e+00 - val_auc: 0.7724\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 119s 593ms/step - loss: 0.2876 - acc: 0.8717 - auc: 0.7720 - val_loss: 0.5256 - val_acc: 0.8147 - val_auc: 0.7724\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 118s 591ms/step - loss: 0.2729 - acc: 0.8781 - auc: 0.7731 - val_loss: 0.3067 - val_acc: 0.9200 - val_auc: 0.7747\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 122s 610ms/step - loss: 0.2838 - acc: 0.8779 - auc: 0.7758 - val_loss: 3.0325 - val_acc: 0.0000e+00 - val_auc: 0.7747\n",
      "\n",
      "Epoch 00075: val_auc improved from 0.77096 to 0.77468, saving model to mynetfin-75-0.00.hdf5\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 126s 628ms/step - loss: 0.2617 - acc: 0.8858 - auc: 0.7737 - val_loss: 1.1763 - val_acc: 0.4547 - val_auc: 0.7741\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2699 - acc: 0.8764 - auc: 0.7746 - val_loss: 0.1067 - val_acc: 1.0000 - val_auc: 0.7753\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 118s 588ms/step - loss: 0.2752 - acc: 0.8811 - auc: 0.7759 - val_loss: 1.6845 - val_acc: 0.2800 - val_auc: 0.7762\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 133s 663ms/step - loss: 0.2821 - acc: 0.8781 - auc: 0.7763 - val_loss: 2.3960 - val_acc: 0.0947 - val_auc: 0.7758\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.2701 - acc: 0.8827 - auc: 0.7756 - val_loss: 0.1456 - val_acc: 1.0000 - val_auc: 0.7761\n",
      "\n",
      "Epoch 00080: val_auc improved from 0.77468 to 0.77607, saving model to mynetfin-80-1.00.hdf5\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2794 - acc: 0.8756 - auc: 0.7765 - val_loss: 0.7036 - val_acc: 0.6400 - val_auc: 0.7768\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 128s 641ms/step - loss: 0.2809 - acc: 0.8757 - auc: 0.7773 - val_loss: 1.9872 - val_acc: 0.0000e+00 - val_auc: 0.7776\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 120s 602ms/step - loss: 0.2724 - acc: 0.8852 - auc: 0.7779 - val_loss: 0.6198 - val_acc: 0.7347 - val_auc: 0.7783\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2655 - acc: 0.8795 - auc: 0.7787 - val_loss: 0.1841 - val_acc: 1.0000 - val_auc: 0.7790\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 121s 605ms/step - loss: 0.2679 - acc: 0.8852 - auc: 0.7794 - val_loss: 1.3814 - val_acc: 0.0000e+00 - val_auc: 0.7803\n",
      "\n",
      "Epoch 00085: val_auc improved from 0.77607 to 0.78027, saving model to mynetfin-85-0.00.hdf5\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 128s 638ms/step - loss: 0.2659 - acc: 0.8797 - auc: 0.7811 - val_loss: 1.0444 - val_acc: 0.3747 - val_auc: 0.7818\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 118s 588ms/step - loss: 0.2861 - acc: 0.8761 - auc: 0.7821 - val_loss: 0.0509 - val_acc: 1.0000 - val_auc: 0.7831\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 118s 589ms/step - loss: 0.2653 - acc: 0.8844 - auc: 0.7842 - val_loss: 1.9720 - val_acc: 0.3600 - val_auc: 0.7844\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 134s 669ms/step - loss: 0.2646 - acc: 0.8844 - auc: 0.7838 - val_loss: 2.1275 - val_acc: 0.0147 - val_auc: 0.7838\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 117s 586ms/step - loss: 0.2743 - acc: 0.8739 - auc: 0.7839 - val_loss: 0.2249 - val_acc: 1.0000 - val_auc: 0.7841\n",
      "\n",
      "Epoch 00090: val_auc improved from 0.78027 to 0.78414, saving model to mynetfin-90-1.00.hdf5\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 0.2672 - acc: 0.8864 - auc: 0.7844 - val_loss: 0.6071 - val_acc: 0.7200 - val_auc: 0.7846\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 126s 631ms/step - loss: 0.2682 - acc: 0.8862 - auc: 0.7850 - val_loss: 1.6276 - val_acc: 0.0000e+00 - val_auc: 0.7855\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 122s 610ms/step - loss: 0.2706 - acc: 0.8872 - auc: 0.7860 - val_loss: 0.6790 - val_acc: 0.6547 - val_auc: 0.7865\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2592 - acc: 0.8877 - auc: 0.7868 - val_loss: 0.0669 - val_acc: 1.0000 - val_auc: 0.7876\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 119s 597ms/step - loss: 0.2656 - acc: 0.8806 - auc: 0.7884 - val_loss: 1.6186 - val_acc: 0.0800 - val_auc: 0.7887\n",
      "\n",
      "Epoch 00095: val_auc improved from 0.78414 to 0.78873, saving model to mynetfin-95-0.08.hdf5\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 128s 640ms/step - loss: 0.2740 - acc: 0.8760 - auc: 0.7891 - val_loss: 1.2557 - val_acc: 0.2947 - val_auc: 0.7895\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 118s 590ms/step - loss: 0.2583 - acc: 0.8841 - auc: 0.7898 - val_loss: 0.1160 - val_acc: 1.0000 - val_auc: 0.7903\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 118s 588ms/step - loss: 0.2739 - acc: 0.8834 - auc: 0.7908 - val_loss: 1.8183 - val_acc: 0.4400 - val_auc: 0.7912\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 132s 659ms/step - loss: 0.2563 - acc: 0.8895 - auc: 0.7906 - val_loss: 2.3799 - val_acc: 0.0000e+00 - val_auc: 0.7904\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 117s 587ms/step - loss: 0.2707 - acc: 0.8811 - auc: 0.7902 - val_loss: 0.2903 - val_acc: 0.9347 - val_auc: 0.7904\n",
      "\n",
      "Epoch 00100: val_auc improved from 0.78873 to 0.79043, saving model to mynetfin-100-0.93.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e74a6b400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epochs = 100\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 200,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 100,\n",
    "    epochs = nb_epochs, \n",
    "    verbose = 1,\n",
    "    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGgfGI7tIzhb"
   },
   "outputs": [],
   "source": [
    "model.save('finalnet.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_znwPHEJMoRL"
   },
   "source": [
    "After training we see a decent result, our net demonstrated up to 88% accuracy on training set with area under curve 0.79, while accuracy on the validation is 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was tough"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
